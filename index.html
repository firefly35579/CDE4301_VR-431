<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>CDE4301 VR-431 Final Report</title>
  <link rel="icon" href="./favicon.ico" type="image/x-icon">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@shoelace-style/shoelace@2.16.0/cdn/themes/light.css" />
  <script type="module"
    src="https://cdn.jsdelivr.net/npm/@shoelace-style/shoelace@2.16.0/cdn/shoelace-autoloader.js"></script>

  <link rel="stylesheet" href="./index.css">

  <link rel="stylesheet" href="./components/team-member/team-member.css">
  <script type="module" src="./components/team-member/team-member.js"></script>

  <link rel="stylesheet" href="./components/table-of-content/table-of-content.css">

  <script type="module" src="./components/image/image-component.js"></script>

  <script type="module" src="./components/video/video.js"></script>

  <link rel="stylesheet" href="./components/references/references.css">

  <link rel="stylesheet" href="./components/scroll-to-top/scroll-to-top.css">
  <script src="./components/scroll-to-top/scroll-to-top.js"></script>

  <script src="./components/table-component/table-component.js"></script>

  <link href="https://unpkg.com/gridjs/dist/theme/mermaid.min.css" rel="stylesheet" />
</head>

<body>
  <div class="content">
    <h1>VR-431 Postpartum Haemorrhage VR Training Simulation</h1>

       <!-- This is the team member component use to display details about your team members -->
       <div class="team-member-wrapper">
        <team-member avatar="assets/Tristan.jpg" name="Tristan Tan" department="Mechanical Engineering"
          year="2025"></team-member>
        <team-member avatar="assets/KC.jpg" name="Kirsten Negapatan" department="Mechanical Engineering"
          year="2025"></team-member>
      </div>
  
      <!-- This is a divide from the shoelace library for aesthetic purpose -->
      <sl-divider></sl-divider>
  
      <!-- This is the table-of-content component use to define all of the link directly to each section -->
      <div class="table-of-content">
        <h2>Table of Contents</h2>
        <sl-tree>
          <sl-tree-item expanded>
            <a href="#section-header-0">0. Acknowledgement</a>
          </sl-tree-item>
      
          <sl-tree-item expanded>
            <a href="#section-header-1">1. Introduction</a>
            <sl-tree-item>
              <a href="#sub-section-1-header-1">1.1. Problem Statement</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-1-header-2">1.2. Background</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-1-header-3">1.3. Novelty and Value Proposition</a>
            </sl-tree-item>
          </sl-tree-item>
      
          <sl-tree-item expanded>
            <a href="#section-header-2">2. Design Strategy</a>
            <sl-tree-item>
              <a href="#sub-section-2-header-1">2.1. Subject Matter Research</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-2-header-2">2.2. Storyboarding</a>
            </sl-tree-item>
          </sl-tree-item>
      
          <sl-tree-item expanded>
            <a href="#section-header-3">3. VR Application Development - Iteration 1</a>
            <sl-tree-item>
              <a href="#sub-section-3-header-1">3.1. Application Flow</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-3-header-2">3.2. Unity Set-Up</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-3-header-3">3.3. Ensuring Accurate-to-Life Scale</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-3-header-4">3.4. Assembling Delivery Ward Environment</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-3-header-5">3.5. App Functionability: Poke Interactable</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-3-header-6">3.6. Iteration 1 Walkthrough</a>
            </sl-tree-item>
            <sl-tree-item expanded>
              <a href="#sub-section-3-header-7">3.7. Preliminary User Testing</a>
              <sl-tree-item>
                <a href="#sub-section-3-header-7-1">3.7.1 Usability Feedback</a>
              </sl-tree-item>
              <sl-tree-item>
                <a href="#sub-section-3-header-7-2">3.7.2 App Design Feedback</a>
              </sl-tree-item>
              <sl-tree-item>
                <a href="#sub-section-3-header-7-3">3.7.3 User Study Design Feedback</a>
              </sl-tree-item>
              <sl-tree-item>
                <a href="#sub-section-3-header-7-4">3.7.4 Data Analysis Feedback</a>
              </sl-tree-item>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-3-header-6">3.8. Hypothesis</a>
            </sl-tree-item>
          </sl-tree-item>
      
          <sl-tree-item expanded>
            <a href="#section-header-4">4. VR Application Development - Iteration 2</a>
            <sl-tree-item>
              <a href="#sub-section-4-header-1">4.1. Summary of Feedback and Improvements Implemented</a>
            </sl-tree-item>
            <sl-tree-item expanded>
              <a href="#sub-section-4-header-2">4.2 Improved User Study Plan</a>
              <sl-tree-item>
                <a href="#sub-section-4-header-2-1">4.2.1 Control Group Materials for Phase 1: Learn</a>
              </sl-tree-item>
              <sl-tree-item>
                <a href="#sub-section-4-header-2-2">4.2.2 Control Group Materials for Phase 2: Practice</a>
              </sl-tree-item>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-4-header-3">4.3. Iteration 2 Walkthrough</a>
            </sl-tree-item>
            <sl-tree-item expanded>
              <a href="#sub-section-4-header-4">4.4. User Study Round 1</a>
              <sl-tree-item>
                <a href="#sub-section-4-header-4-1">4.4.1 Usability Feedback</a>
              </sl-tree-item>
              <sl-tree-item>
                <a href="#sub-section-4-header-4-2">4.4.2 App Design Feedback</a>
              </sl-tree-item>
              <sl-tree-item>
                <a href="#sub-section-4-header-4-3">4.4.3 User Study Design Feedback</a>
              </sl-tree-item>
            </sl-tree-item>
          </sl-tree-item>
      
          <sl-tree-item expanded>
            <a href="#section-header-5">5. VR Application Development - Iteration 3</a>
            <sl-tree-item>
              <a href="#sub-section-5-header-1">5.1. Summary of Feedback and Improvements</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-5-header-2">5.2. App Functionality: Grab Interactable</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-5-header-3">5.3. App Functionality: Adding Images</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-5-header-4">5.4. App Functionality: Adding Sound Effects</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-5-header-5">5.5. User Study Phase 3: Test – Asset Improvement</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-5-header-6">5.6. Iteration 3 Walkthrough</a>
            </sl-tree-item>
            <sl-tree-item expanded>
              <a href="#sub-section-5-header-7">5.7. User Study Round 2</a>
              <sl-tree-item>
                <a href="#sub-section-5-header-7-1">5.7.1 App Design Feedback</a>
              </sl-tree-item>
            </sl-tree-item>
          </sl-tree-item>
      
          <sl-tree-item expanded>
            <a href="#section-header-6">6. VR Application Development - Iteration 4</a>
            <sl-tree-item>
              <a href="#sub-section-6-header-1">6.1. Summary of Feedback and Improvements</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-6-header-2">6.2. Learning Material Development: Inclusion of Common Real-Life Objects to Enhance Understanding of Scale</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-6-header-3">6.3. App Functionality: Object Collider</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-6-header-4">6.4. Revised User Study Documents</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-6-header-5">6.5. Iteration 4 Walkthrough</a>
            </sl-tree-item>
            <sl-tree-item expanded>
              <a href="#sub-section-6-header-6">6.6. Iteration 4 Feedback</a>
              <sl-tree-item>
                <a href="#sub-section-6-header-6-1">6.6.1 Usability Feedback</a>
              </sl-tree-item>
              <sl-tree-item>
                <a href="#sub-section-6-header-6-2">6.6.2 App Design Feedback</a>
              </sl-tree-item>
            </sl-tree-item>
          </sl-tree-item>
      
          <sl-tree-item expanded>
            <a href="#section-header-7">7. Results & Analysis</a>
            <sl-tree-item>
              <a href="#sub-section-7-header-1">7.1. Results</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-7-header-2">7.2. Analysis</a>
            </sl-tree-item>
          </sl-tree-item>
      
          <sl-tree-item expanded>
            <a href="#section-header-8">8. Discussions & Recommendations</a>
            <sl-tree-item>
              <a href="#sub-section-8-header-1">8.1. Key Findings</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-8-header-2">8.2. Project Limitations</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-8-header-3">8.3. Future Work & Recommendations</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-8-header-4">8.4. Conclusion</a>
            </sl-tree-item>
          </sl-tree-item>
      
          <sl-tree-item expanded>
            <a href="#section-header-9">9. Project Workload Distribution</a>
            <sl-tree-item>
              <a href="#sub-section-9-header-1">9.1. Kirsten Clare M. Negapatan - Contribution Summary</a>
            </sl-tree-item>
            <sl-tree-item>
              <a href="#sub-section-9-header-2">9.2. Tristan Tan Tng En - Contribution Summary</a>
            </sl-tree-item>
          </sl-tree-item>
      
          <sl-tree-item>
            <a href="#references">10. References</a>
          </sl-tree-item>

          <sl-tree-item expanded>
            <a href="#section-header-11">11. Appendix</a>
          </sl-tree-item>
        </sl-tree>
      </div>
      <sl-divider></sl-divider>
  
      <div>
  
        <!-- This is an example of what a section might look like -->
        <div id="section-header-1">
          <h2> 0. Acknowledgement </h2>
          <p>
            We would like to express our deepest appreciation to the many people who gave us guidance throughout this year-long journey, and who provided us with the tools necessary to develop our product in a more meaningful and effective way than we would have on our own. 

Special gratitude to our project supervisor, Dr. Khoo Eng Tat, who offered stimulating and pertinent suggestions and encouragement every week, and helped us coordinate our project. Their constant encouragement and insightful suggestions helped us immensely throughout our project.

We would like to acknowledge with much appreciation the crucial role of Dr. Arundhati and Dr Abhiram Kanneganti, who gave us indispensable advice and suggestions in completing the project. 

We would like to express our deepest thanks to Liu Chang, who has assisted us immensely throughout our projects in the iDP programme and whose kind advice and encouragement helped inspire us to make the project the best it could be.

We would like to express our gratitude to Cheng Haojie, who provided us with valuable assistance and suggestions to improve our project.

We would like to express our great appreciation for Charmaine, who provided invaluable help and advice with our simulation. 

Furthermore, we would like to express our deepest thanks to all the users who took the time to participate in our user studies and provide helpful feedback.
        </p>
        </div>
      </div>
  
      <br />
      <sl-divider></sl-divider>
      <div>
        <div id="section-header-1">
          <h2>1. Introduction</h2>          
        </div>
  
        <div id="sub-section-1-header-1">
          <h3>1.1. Problem Statement</h3>
          <p>
            Postpartum Hemorrhage (PPH) is one of the most critical and life-threatening obstetric emergencies encountered in clinical practice. It is traditionally defined as a blood loss of more than 500 mL following vaginal delivery or more than 1,000 mL following cesarean delivery, with severe PPH involving blood loss greater than 1,500 mL or associated hemodynamic instability (Bienstock et al., 2021). PPH accounts for approximately 27% of all maternal deaths worldwide, making it the leading direct cause of maternal mortality globally (Say et al., 2024). Each year, about 14 million women experience PPH resulting in about 70,000 maternal deaths globally (WHO, 2023). The urgency and complexity of managing PPH require that healthcare professionals, particularly those in obstetrics and gynecology, be well-trained in recognizing early signs of excessive bleeding and executing prompt interventions.
          </p>
          <p>
            In Singapore, while maternal mortality rates are low compared to global averages, PPH remains a significant cause of maternal morbidity, contributing to emergency hysterectomies, ICU admissions, and long-term complications such as anemia, infection, and psychological trauma (De Silva et al., 2021). Studies have shown that up to 5% of deliveries worldwide result in PPH, with uterine atony being the most common cause, causing approximately 70% of all cases (Wormer et al., 2024).
          </p>
          <p>
            To diagnose PPH, medical staff need to determine a quantitative measure of blood loss during the third stage of labour (WHO, 2023).  The most common method used to assess and meausre this blood loss is visual estimation (WHO, 2023). However, visual estimation is widely considered to be inaccurate because it can mis-estimate blood loss to a large degree, in particular leading to under-estimation at higher volumes of blood loss. The underestimation of blood loss can be approximately 16% to 41%, and can delay the diagnosis of PPH and the administration of life-saving interventions including uterotonic agents, uterine massage, and surgical procedures (Toledo et al.).
          </p>
        </div>
  
        <div id="sub-section-1-header-2">
          <h3>1.2. Background</h3>
          <p>
            Despite its clinical importance, training for PPH recognition and management remains limited and inconsistent across medical institutions (Akter et al., 2022). At the National University of Singapore Yong Loo Lin School of Medicine (NUS YLLSOM), students often only receive didactic training on PPH; lectures where they focus on theory (A. Kanneganti, personal communication, March 21, 2025). They do not have hands-on training for estimating blood loss, they simply learn from the textbook. Below are some pages from the textbook:
          </p>
          
          <!-- Start of the Textbook Gallery -->
          <div class="gallery-container medical-gallery">
            <button id="prev-textbook" class="gallery-button">←</button>
            <img id="gallery-image-textbook" src="assets/pg177.jpg" alt="Textbook Frame 1">
            <button id="next-textbook" class="gallery-button">→</button>
          </div>
          <p id="gallery-caption-textbook" class="gallery-caption">1 of X</p>

          <p>  
            It is difficult for these lecture sessions to replicate the dynamic, real-time progression of PPH in an actual delivery setting, nor do they provide an objective, feedback-driven platform for blood loss estimation and clinical decision-making. Furthermore, without repeated exposure or the ability to practice in varied clinical contexts, students may struggle to develop confidence and accuracy in identifying when PPH is occurring and how best to respond.
          </p>
        </div>

        <div id="sub-section-1-header-3"></div>
          <h3>1.3. Novelty and Value Proposition</h3>
          <p>
            Given the high stakes of PPH management and the limitations of current training methods, it is crucial to introduce simulation-based education that can replicate real-world obstetric emergencies. Virtual Reality (VR) offers a promising solution by enabling immersive, repeatable, and feedback-rich experiences for medical students. We propose a VR training simulation focused on blood loss estimation and early PPH detection which can expose students to a range of bleeding scenarios, allowing them to hone their observational skills, make time-sensitive decisions, and gain a deeper understanding of PPH progression and treatment protocols. By incorporating visual cues and instantaneous feedback, the VR simulation will help students learn better and develop proficiency in recognizing and managing PPH effectively. NUS medical students are also given a VR headset so access to a VR simulation to practice the relevant skills when they need will give them better exposure and increase the frequency of practice they can have, ultimately helping enhance their education. The VR simulation will also utilise to-scale assets and give users a better sense of scale and context so that they can more easily relate and internalise their learning.
          </p>
          <p>
            By improving the quality of PPH training through VR, we aim to address the global call for better maternal care and enhance the readiness of future clinicians in managing one of obstetrics’ most dangerous complications. Early recognition and effective intervention not only save lives but also reduce the risk of long-term maternal health consequences, alleviate healthcare burdens, and improve patient confidence in maternal care systems. We hope to help enhance NUS medical students’ decision-making accuracy, knowledge retention, and ultimately contribute to better clinical outcomes for maternal healthcare in Singapore.
          </p>
        </div>
  
      <br />
      <sl-divider></sl-divider>
      <div>
        <div id="section-header-2">
          <h2>2. Design Strategy</h2>
          
        </div>
  
        <div id="sub-section-2-header-1">
          <h3>2.1 Subject Matter Research</h3>
          <p>
            CLT highlights the critical balance between working memory’s limitations and long-term memory’s capacity to store schemas. Effective learning occurs when instructional designs optimise cognitive load by minimising extraneous demands, enabling learners to focus on intrinsic and germane processes (Centre for Education Statistics and Evaluation [CESE], 2017). VR’s immersive and intuitive interfaces uniquely align with CLT principles by presenting complex medical scenarios in an engaging, contextually rich format. In the case of PPH, VR simulations minimise extraneous distractions present in a typical classroom, and direct learners’ attention to mastering essential decision-making processes. The multisensory inputs offered by VR create a highly engaging environment that reinforces cognitive schema acquisition (Fuoad et al., 2022). Such immersive learning environments have been shown to significantly reduce cognitive overload while promoting deeper retention of complex tasks, making VR a powerful tool for integrating CLT into medical education (Andersen et al., 2016).
  
          </p>
  
          
        </div>
  
        <div id="sub-section-2-header-2">
          <h3>2.2 Storyboarding</h3>
          <p>
            Embodied cognition posits that cognitive processing is deeply rooted in the body’s physical interactions with its environment. This theory underscores the importance of active, experiential learning, suggesting that physical engagement enhances the depth and retention of knowledge (Skulmowski, 2018). VR bridges the gap between theoretical understanding and hands-on practice by allowing learners to “inhabit” the learning experience. In this case, managing a simulated PPH case in VR allows students to rehearse life-saving interventions, such as fundal massage and oxytocin administration, within a realistic but safe virtual environment. This hands-on, immersive approach strengthens neural connections associated with procedural tasks, bridging the gap between passive learning and active skill acquisition (Tene et al., 2024). Embodied experiences in VR have been shown to lead to enhanced problem-solving capabilities and long-term retention, emphasising its transformative potential in medical training (Steen et al., 2024).
          </p>

          <p>
            Below is an image gallery showcasing the initial storyboard we made for VR PPH training in general in medical education.
          </p>
  
          <!-- Start of the Image Gallery -->
          <div class="gallery-container">
            <button id="prev" class="gallery-button">←</button>
            <img id="gallery-image" src="assets/image1.png" alt="Storyboard Frame 1">
            <button id="next" class="gallery-button">→</button>
          </div>
          <p id="gallery-caption" class="gallery-caption">Step 1 of 46</p>
  
          <p>
            Below is an image gallery showcasing the final storyboard for our VR Simulation.
          </p>
                
          <div class="gallery-container">
            <button id="prev-vr" class="gallery-button">←</button>
            <img id="gallery-image-vr" src="" alt="VR Storyboard Frame" />
            <button id="next-vr" class="gallery-button">→</button>
          </div>
          <div id="gallery-caption-vr" class="gallery-caption"></div>
          
          <p>
            Below are pages from the PRactical Obstetric Multi-Professional (PROMPT) Course and Trainer's Manual which was used as our reference for our storyboard.
          </p>
  
         
          <!-- Start of the Medical Reference Gallery -->
          <div class="gallery-container medical-gallery">
            <button id="prev-medical" class="gallery-button">←</button>
            <img id="gallery-image-medical" src="assets/pg178.jpg" alt="Medical Reference Frame 1">
            <button id="next-medical" class="gallery-button">→</button>
          </div>
          <p id="gallery-caption-medical" class="gallery-caption">1 of X</p>
  
          <p>
            In the control group, participants will receive traditional lecture-based instruction, focusing on the theoretical principles of PPH management and problem-solving strategies. This method mirrors the conventional approach in medical education, providing a benchmark for comparing the efficacy of VR-based learning.
          </p>

          <p>
            The integration of Cognitive Load Theory and Embodied Cognition forms a robust theoretical foundation for VR-based medical education. By leveraging VR’s immersive capabilities, this approach optimises cognitive resources, engages sensory-motor systems, and fosters structured problem-solving skills. These elements collectively enable medical students to transition from passive theoretical learning to active, experiential mastery, ensuring readiness for real-world clinical challenges and contributing to improved patient care outcomes.
          </p>
        </div>
      </div>
  
      <br />
      <sl-divider></sl-divider>
      <div>
        <div id="section-header-3">
          <h2>3. VR Application Development – Iteration 1</h2>
        </div>
  
        <div id="sub-section-3-header-1">
          <h3>3.1 Application Flow</h3>
          <p>
            The application was initially structured such that each interaction question resided within its own Unity scene. These scenes were linked via a C# script that managed navigation using button-triggered scene transitions. However, this approach significantly increased the application’s file size and resulted in long build times – approximately ten minutes per build – which impeded rapid prototyping.
          </p>

          <div class="centered-figure">
            <img src="assets/Build Settings Scenes.jpg" alt="Build Settings Scenes" class="centered-image" />
            <div class="image-caption">Figure 1: The Various Scenes in Our First Project File, as Shown in the Build Settings Window.</div>
          </div>
          
          <p>
            To address this issue, we transitioned to a more efficient architecture by consolidating all interactions into a single scene. Each question was assigned a distinct canvas, and we toggled their visibility using GameObject.SetActive() in response to user input. This approach, combined with Unity’s XR Simple Interactable system, reduced the build time to approximately 30 seconds and enabled a more agile development cycle.
          </p>
          
          <div class="centered-figure">
            <img src="assets/Learner Project File Hierarchy.jpg" alt="Learner Project File Hierarchy" class="centered-image" />
            <div class="image-caption">Figure 2: The Hierarchy of Our Leaner Project File, Using a New GameObject to House Various ‘Scenes’ within the Hierarchy of a Single Unity Scene.</div>
          </div>

          <div class="centered-figure">
            <img src="assets/XR Simple Interactable.jpg" alt="XR Simple Interactable" class="centered-image" />
            <div class="image-caption">Figure 3: The Components used to enable moving from one scene to the next using XR Simple Interactable</div>
          </div>
        </div>
  
        <div id="sub-section-3-header-2">
          <h3>3.2 Unity Set-Up</h3>
          <p>
            Our initial development began with a Unity project inherited from a prior research fellow. This project, however, was burdened with numerous complex plugins and packages, leading to over 80 compilation errors. 
          </p>

          <div class="centered-figure">
            <img src="assets/3.2 1.jpg" alt="Original Project File" class="centered-image" />
            <div class="image-caption">Figure 4: The Original Project File with 80+ Compilation Errors</div>
          </div>

          <p>
            After consulting with researchers at the Immersive Reality Lab, we followed a recommended clean setup process outlined in a set of slides, creating a fresh Unity project with only essential packages and plugins. This approach greatly simplified debugging and streamlined subsequent development.
          </p>
        </div>

        <div id="sub-section-3-header-3">
          <h3>3.3 Ensuring Accurate-to-Life Scale</h3>
          <p>
            To maintain realism, we benchmarked our VR environment against the Apartment Kit sample scene, which had already been calibrated for accurate real-world scaling. 
          </p>

          <div class="centered-figure">
            <img src="assets/3.3 1.png" alt="Apartment Kit" class="centered-image" />
            <div class="image-caption">Figure 5: The Apartment Kit sample environment used to scale our own app.</div>
          </div>

          <p>
            We calibrated our assets accordingly, referencing physical items such as counters available in our homes, to ensure immersive and believable spatial proportions.
          </p>
        </div>

        <div id="sub-section-3-header-4">
          <h3>3.4 Assembling Delivery Ward Environment</h3>
          <p>
            The environment design prioritised a balance between realism and clarity. We used assets commissioned by previous student teams to assemble a scene that closely resembled a delivery ward while remaining visually uncluttered. This allowed users to focus on the training objective without unnecessary distractions
          </p>

          <div class="centered-figure">
            <img src="assets/3.4 1.png" alt="Delivery Ward Environment" class="centered-image" />
            <div class="image-caption">Figure 6: The delivery ward environment created using previously-commissioned assets. </div>
          </div>
        </div>

        <div id="sub-section-3-header-5">
          <h3>3.5 App Functionality: Poke Interactable</h3>
          <p>
            We adopted Unity’s XR Poke Interactable system, as demonstrated in a YouTube tutorial (Fist Full of Shrimp, 2023), to implement poke interactions. This required the configuration of a box collider, an XR Poke Filter specifying poke direction, as well as XR Simple Interactable for triggering responses (e.g., canvas transitions or sound playback).
          </p>
        </div>

        <div id="sub-section-3-header-6">
          <h3>3.6 Iteration 1 Walkthrough</h3>
          <p>
            The completed flow featured multiple canvases representing sequential questions. Users navigated through them using poke-enabled buttons. The demonstration video is as shown.
          </p>
          <video-component 
          tag="VR Video 1" 
          source="https://www.youtube.com/embed/42y3vopfRUA"
          subtitle="Iteration 1"
          ></video-component>
        </div>

        <div id="sub-section-3-header-7">
          <h3>3.7 Preliminary User Testing</h3>
          <p>
            Feedback was obtained through a pilot session with Immersive Reality Lab members Liu Chang and Haojie. Their insights informed several critical design and usability improvements.
          </p>

          <div class="centered-figure">
            <img src="assets/3.7 1.jpg" alt="Liu Chang" class="centered-image" />
            <div class="image-caption">Figure 7: Immersive reality expert, Liu Chang, trying our app during the preliminary testing round. </div>
          </div>
        </div>

        <div id="sub-section-3-header-7-1">
          <h3>3.7.1 Usability Feedback</h3>
          <video-component 
          tag="Z-fighting" 
          source="https://www.youtube.com/embed/1j4HGfP6lc4" 
          subtitle="Z-fighting Clip"
          ></video-component>
          <p>
            Z-fighting on walls needed correction. This caused the wall to glitch throughout the user’s experience, leading to visual discomfort.

            Furthermore, the resolution for the UI elements was low, leading to pixelated edges and corners.
            
            Excessive gaze movement between UI and in-scene objects reduced user comfort and focus. 
          </p>
        </div>

        <div id="sub-section-3-header-7-2">
          <h3>3.7.2 App Design Feedback</h3>
          <div class="centered-figure">
            <img src="assets/3.7.2 1.png" alt="Confusing Feedback Text" class="centered-image" />
            <div class="image-caption">Figure 8: Original confusing feedback text. </div>
          </div>
          <p>
            Feedback messaging was generic and not tailored to the type of error (e.g., over- vs underestimation of blood loss). Our users recommended context-sensitive messaging for greater educational value. 
          </p>
          <div class="centered-figure">
            <img src="assets/3.7.2 2.png" alt="Original Summary Panel" class="centered-image" />
            <div class="image-caption">Figure 9: Original summary panel shown after the user inputs their answer, showing the breakdown of assets present in the scene. </div>
          </div>
          <p>
            Our users also noted that asset icons on the summary panel were not to scale, potentially misleading users. 
          </p>
        </div>

        <div id="sub-section-3-header-7-3">
          <h3>3.7.3 User Study Design Feedback</h3>
          <p>
            Initially, due to a limited timeframe and lack of access to relevant medical students for user testing, we were faced with the issue of a small sample size for our user validation studies. Therefore, we planned to simply gather qualitative user feedback on our application, and progressively iterate on the application using this feedback.
          </p>
          <p>
            However, our study participants proposed a more structured comparison between an experimental group undergoing VR training and a control group receiving the textbook training that medical students are currently undergoing.  At the end, both control and experimental groups would undergo the same in-person test, using life-sized physical assets mimicking the appearance of the blood collection instruments. Through data collection and statistical analysis, meaningful connections or interesting trends may arise. 
          </p>
        </div>

        <div id="sub-section-3-header-7-4">
          <h3>3.7.4 Data Analysis Feedback</h3>
          <p>
            Our participants advised tracking response accuracy and completion time per question, visualised through boxplots. They recommended comparing distributions between control and experimental groups to assess learning efficacy.
          </p>
        </div>

        <div id="sub-section-3-header-8">
          <h3>3.8 Hypothesis</h3>
          <p>
            After this first round of preliminary testing, we came up with a hypothesis: participants exposed to the VR simulation would demonstrate higher accuracy and faster response times when estimating postpartum blood loss than those trained using traditional materials.
          </p>
        </div>

        <br />
      <sl-divider></sl-divider>
      <div>
        <div id="section-header-4">
          <h2>4. VR Application Development – Iteration 2</h2>
        </div>

        <div id="sub-section-4-header-1">
          <h3>4.1 Summary of Feedback and Improvements Implemented</h3>
        </div>
        <p>
          Due to time constraints – specifically, the user study scheduled just 12 hours after the previous feedback session – not all of their suggestions could be implemented in Iteration 2. However, these recommendations were subsequently addressed in Iteration 3. The following table outlines only those improvements that were incorporated into Iteration 2.
        </p>
        <div class="centered-figure">
          <img src="assets/4.1 1.jpg" alt="Summary of Feedback and Improvements" class="centered-image" />
        </div>

        <div id="sub-section-4-header-2">
          <h3>4.2 Improved User Study Plan</h3>
          <p>
            Our user study flow is as depicted in the following flowchart.
          </p>

          <div class="centered-figure">
            <img src="assets/4.2 1.png" alt="User Study Flow" class="centered-image" />
            <div class="image-caption">Figure 10: The flowchart used to brief our participants on what to expect during the user study.</div>
          </div>

          <p>
            Both control and experimental groups followed an identical three-phase structure: Learn → Practice → Test. The instructional materials used in the control group's "Learn" phase were carefully aligned with the content delivered in the experimental group's VR experience. Similarly, the practice activities were standardised across both groups to ensure comparability
          </p>          
        </div>
  
        <div id="sub-section-4-header-2-1">
          <h3>4.2.1 Control Group Materials for Phase 1: Learn</h3>
          <p>
            Participants in the control group received a printed document during the initial five-minute "Learn" phase.
          </p>
          <div class="centered-figure">
            <img src="assets/4.2.1 1.jpg" alt="Learn Handout 1" class="centered-image" />
          </div>
          <div class="centered-figure">
            <img src="assets/4.2.1 2.jpg" alt="Learn Handout 2" class="centered-image" />
            <div class="image-caption">Figure 11: The ‘Phase 1’ document provided to control group participants.</div>
          </div>

          <div id="sub-section-4-header-2-2">
            <h3>4.2.2 Control Group Materials for Phase 2: Practice</h3>
            <p>
              In the subsequent five-minute "Practice" phase, control group participants received a new document. Access to the original learning material was restricted to encourage recall and active practice.
            </p>
            <div class="centered-figure">
              <img src="assets/4.2.2 1.jpg" alt="Practice Handout 1" class="centered-image" />
            </div>
            <div class="centered-figure">
              <img src="assets/4.2.2 2.jpg" alt="Practice Handout 2" class="centered-image" />
            </div>
            <div class="centered-figure">
              <img src="assets/4.2.2 3.jpg" alt="Practice Handout 3" class="centered-image" />
            </div>
            <div class="centered-figure">
              <img src="assets/4.2.2 4.jpg" alt="Practice Handout 4" class="centered-image" />
            </div>
            <div class="centered-figure">
              <img src="assets/4.2.2 5.jpg" alt="Practice Handout 5" class="centered-image" />
            </div>
            <div class="image-caption">Figure 12: The ‘Phase 2’ document provided to control group participants.</div>


        <div id="sub-section-4-header-3">
          <h3>4.3 Iteration 2 Walkthrough</h3>
          <p>
            A video walkthrough documenting the second iteration’s functionality and flow of the application is shown.
          </p>
          <video-component 
          tag="Iteration 2" 
          source="https://youtube/embed/exoZMj_zyx4"
          subtitle="Iteration 2"
          ></video-component>
          
        </div>
  
        <div id="sub-section-4-header-4">
          <h3>4.4 User Study Round 1</h3>
          <p>
            The first round of user testing involved four university students, each 25 years old, with minimal prior exposure to VR technology and limited medical knowledge.
          </p>
          <div class="centered-figure">
            <img src="assets/4.4 1.jpg" alt="User Study Round 1" class="centered-image" />
          </div>
          <div class="image-caption">Figure 13: Participants engaged in the VR simulation during the first round of user testing</div>
        </div>
  
        <div id="sub-section-4-header-4-1">
          <h3>4.4.1 Usability Feedback</h3>
          <p>
            Participants noted difficulty in noticing relevant assets within the virtual environment, as these were scattered around the room. They recommended implementing visual cues to direct attention more effectively.
          </p>

          <p>
            Several participants also reported that they skimmed the initial instructions due to excitement about using the VR technology. As a result, they mistakenly memorised the physical dimensions of the medical items rather than their blood absorption capacities. They recommended incorporating clearer reminders about what information was critical to retain, and at what stage of the simulation.
          </p>
        </div>


        <div id="sub-section-4-header-5">
          <h3>4.5 Statistical Analysis</h3>
          <p>
            A rigorous statistical analysis framework will be employed to ensure the reliability and validity of the findings:
          </p>
        
          <ul>
            <li>
              <strong>Descriptive Statistics:</strong> To summarise the central tendencies (mean, median) and variability (standard deviation) within each group.
            </li>
            <li>
              <strong>Inferential Statistics:</strong> Independent samples t-tests will compare the means of the VR and control groups for each performance metric, identifying statistically significant differences. Additionally, Analysis of Variance (ANOVA) will be used to examine interactions between instructional methods and participant demographics, such as prior medical knowledge.
            </li>
            <li>
              <strong>Reliability Analysis:</strong> Cronbach’s alpha (≥0.7 threshold) will assess the internal consistency of the assessment instruments, ensuring that the measurements are robust and reliable.
            </li>
            <li>
              <strong>Outlier Management:</strong> Standardised residuals will be calculated to detect and address outliers, ensuring data integrity. Sensitivity analyses will further validate findings by testing the robustness of results under different assumptions.
            </li>
          </ul>
        
          <p>
            This analytical approach not only provides robust statistical validation but also enables a comprehensive understanding of the factors influencing problem-solving performance, ensuring that the results are both reliable and generalisable.
          </p>
  
        </div>
      </div>
  
      <br />
      <sl-divider></sl-divider>
      <div>
        <div id="section-header-5">
          <h2>5. Anticipated Results </h2>
          <p>
            This study hypothesises that participants in the Virtual Reality (VR) group will exhibit superior performance across all evaluated metrics compared to the control group. Specifically, we anticipate the following outcomes:
          </p>
        
          <ul>
            <li>
              <strong>Enhanced Problem-Solving Efficiency:</strong> VR participants are expected to demonstrate an ability to navigate complex scenarios with fewer steps and minimal errors, reflecting enhanced cognitive schema development. The realistic and interactive nature of VR provides a platform allowing learners to internalise systematic approaches to clinical challenges more effectively than traditional lecture-based methods (Plackett et al., 2022). This efficiency is particularly critical in high-pressure situations like PPH, where swift and accurate decisions can significantly impact patient outcomes.
            </li>
            <li>
              <strong>Accelerated Response Times:</strong> Immersive VR environments simulate the urgency of real-world medical emergencies, training participants to process information and make decisions under pressure (Mergen et al., 2024). This hands-on exposure is anticipated to develop quicker cognitive reflexes, better preparing participants to respond promptly and effectively in actual clinical scenarios (Einloft et al., 2024).
            </li>
            <li>
              <strong>Reduced Dependence on External Hints:</strong> By fostering a deeper understanding of clinical decision-making through experiential learning, VR is expected to boost participants’ confidence and independence. This reduction in reliance on external prompts during problem-solving tasks reflects an increased capacity for autonomous reasoning, a critical competency in unpredictable, high-stakes medical settings.
            </li>
          </ul>
        
     

          <video-component 
          tag="VR Video 2" 
          source="https://youtu.be/embed/C9vL3Ym4IdQ"
          subtitle="Iteration 2"
      ></video-component>
          
          <video-component 
          tag="VR Video 3" 
          source="https://youtu.be/embed/qo9Jh0-pVxc"
          subtitle="Iteration 3"
      ></video-component>

          <video-component 
          tag="VR Video 4" 
          source="https://www.youtube.com/embed/0T2rt3Yr6hI"
          subtitle="Iteration 4"
      ></video-component>

          <p>
            These results are anticipated to validate VR’s transformative potential as a tool for advancing cognitive adaptability in medical education. The structured application of Polya’s Problem-Solving Framework within the VR simulations reinforces systematic thinking, enabling participants to apply theoretical knowledge in a methodical and pragmatic manner. Unlike passive learning environments, VR engages learners actively, bridging the gap between theory and practice (Tene et al., 2024).
          </p>
        </div>
      </div>
  
      <br />
      <sl-divider></sl-divider>
      <div>
        <div id="section-header-6">
          <h2>6. Challenges and Mitigation Strategies</h2>
        </div>
  
        <div id="sub-section-6-header-1">
          <h3>6.1 Addressing the Novelty Effect</h3>
          <p>
            The novelty effect refers to the initial cognitive overload and distraction learners may experience when first interacting with new technologies like VR. This effect can divert focus from learning objectives to navigating the unfamiliar technology, thereby diminishing educational outcomes (Miguel-Alonso et al., 2024). To mitigate this challenge, a multi-faceted approach will be employed:
          </p>
        
          <ul>
            <li>
              <strong>Comprehensive Pre-Exposure Training:</strong> A step-by-step tutorial will introduce participants to the VR interface and mechanics, ensuring a seamless transition into the simulation. This preparatory phase will include hands-on practice to familiarise users with navigation, controls, and system interactions, reducing anxiety and cognitive strain.
            </li>
            <li>
              <strong>Incremental Immersion Strategy:</strong> The VR simulation will be structured progressively, starting with basic, low-stakes interactions such as clicking a simple button and gradually advancing to more complex interactions such as following a set of guiding hands. This scaffolding approach ensures learners build confidence and competence without feeling overwhelmed.
            </li>
            <li>
              <strong>Ongoing Facilitator Support:</strong> Dedicated facilitators will be available throughout the simulation sessions to provide real-time assistance, address technical issues, and refocus participants on the educational objectives. Their presence ensures continuous engagement and minimises interruptions.
            </li>
          </ul>
        
          <p>
            These measures not only mitigate the novelty effect but also enhance participants’ readiness to engage deeply with the content, allowing the VR experience to serve as a robust learning platform.
          </p>
        </div>
  
        <div id="sub-section-6-header-2">
          <h3>6.2 Resource Constraints</h3>
          <p>
            The development and deployment of VR simulations pose resource challenges, including high costs, extensive time commitments, and the need for technical expertise. To address these constraints, the following mitigation strategies will be employed:
          </p>
        
          <ul>
            <li>
              <strong>Strategic Institutional Partnerships:</strong> A close collaborative relationship has been established with the Obstetrics & Gynaecology Department at National University of Singapore Yong Loo Lin School of Medicine to help ensure that our pedagogical approach aligns with industry standards.
            </li>
            <li>
              <strong>Leveraging Existing Resources:</strong> Instead of creating a VR simulation from scratch, the study will adapt existing VR simulations available to us. This approach reduces development costs and accelerates deployment while ensuring reliability and user-friendliness.
            </li>
          </ul>
        
          <p>
            By adopting these measures, the study ensures efficient utilisation of resources while maintaining the high quality and relevance of the VR simulations.
          </p>
  
        </div>
      </div>
  
      <br />
      <sl-divider></sl-divider>
      <div>
        <div id="section-header-7">
          <h2>7. Results & Analysis</h2>
        </div>
        <div id="sub-section-7-header-1">
          <h3>7.1 Results</h3>
        </div>
          <p>
            Below is our Table of Results of our User Studies:
          </p>
          <div class="centered-figure">
            <img src="assets/Results Table.jpg" alt="Results Table" class="large-image" />
          </div>
          <p>
            You may view or download the user test results below:
          </p>
  <a href="https://raw.githubusercontent.com/firefly35579/CDE4301_VR-431/main/assets/VR User Test Results.xlsx" download>Download the Excel File</a>

  <iframe src="https://view.officeapps.live.com/op/embed.aspx?src=https://raw.githubusercontent.com/firefly35579/CDE4301_VR-431/main/assets/VR%20User%20Test%20Results.xlsx"
    width="100%" height="600px" frameborder="0"></iframe>  
    
          <p>
            We managed to conduct a total of 16 user studies. The participants mainly consisted of university peers as well as researchers from the Immersive Reality Lab. The level of prior VR experience was mostly minimal besides the researchers, while the level of prior relevant medical experience was minimal for all the users, i.e. none had significant knowledge of PPH or blood loss estimation prior to the user study. The users were timed to ensure they did not take more than 5 minutes for either the learning phase or the practice phase. 
          </p>
          <p>
            To have a measure of how accurate our users were, we decided to quantify their mistakes made as a percentage of the total number of questions they were tested on, a mistake being a deviation of more than 200 mL from the correct answer. These are highlighted in red in the table. Additionally, if a response was very far off, i.e. a large mistake, they were highlighted as well. If the volume of blood loss was underestimated by 400 mL or more it was highlighted in orange, and if it was overestimated by 400 mL or more it was highlighted in yellow.
          </p>
          <p>
            A few other metrics were also calculated, namely the average answered volume of blood loss for each test question, the number of users that made a mistake for each question, as well as the number of users that made a large mistake for each question. These will be analysed later in Section 7.2.
          </p>
          <p>
            For the purposes of results analysis, the averages and percentages seen at the bottom of the table only included results from the twelve user studies after iteration 2, i.e. the first four user studies were excluded as they were not tested on the same questions as the subsequent twelve. 
          </p>
        </div>
  

  
        <div id="sub-section-7-header-2">
          <h3>7.2 Implications for Curriculum Development</h3>
          <p>
            The anticipated outcomes will provide robust support for integrating VR simulations into competency-based medical curricula, emphasising measurable, outcome-driven learning objectives. By offering controlled, risk-free environments for practising critical medical interventions, VR could complement traditional instruction, particularly in emergency medicine and high-pressure clinical contexts. This research would highlight how VR simulations address current gaps in emergency training and provide invaluable opportunities for iterative learning and skill refinement. The implications extend to reimagining curriculum design to prioritise adaptive, technology-enhanced methods.
          </p>
  
        </div>
  
        <div id="sub-section-7-header-3">
          <h3>7.3 Evidence-Based Educational Practices</h3>
          <p>
            Through a rigorous experimental framework, this research seeks to generate compelling evidence of VR’s cognitive benefits, particularly in teaching critical problem-solving skills. Using standardised evaluation metrics, the study is expected to offer actionable insights into VR’s effectiveness compared to traditional educational approaches. These findings will serve as a guide for policymakers, educators, and curriculum developers, enabling data-driven decisions on integrating VR into broader educational strategies.
          </p>
        </div>
  
        <div id="sub-section-7-header-4">
          <h3>7.4 Scalability and Accessibility</h3>
          <p>
            A key innovation of this research lies in demonstrating VR’s potential as a scalable and cost-effective educational solution. By focusing on PPH—a high-stakes medical scenario—the study illustrates how VR can democratise advanced training even in resource-limited settings. The ability to simulate complex emergencies repeatedly and consistently ensures equitable access to high-quality training modules, regardless of institutional constraints. This research may also lay the groundwork for implementing VR in non-medical fields, such as engineering, aviation, and business, emphasising its versatility and universal applicability.
          </p>
  
        </div>
  
      </div>
  
      <br />
      <sl-divider></sl-divider>
      <div>
        <div id="section-header-8">
          <h2>8. Next Steps</h2>
          <p>
            To outline the project’s progression in the coming semester, please refer to the Gantt chart provided. This chart highlights key milestones and activities, including:
          </p>
        
          <ul>
            <li>
              <strong>Weeks 1–3: Participant Recruitment</strong>
              <ul>
                <li>Develop recruitment materials such as emails.</li>
                <li>Find participants via our contacts with NUS YLLSOM’s O&G Department.</li>
                <li>Screen potential participants based on inclusion and exclusion criteria.</li>
                <li>Finalise the participant pool and schedule study sessions.</li>
              </ul>
            </li>
            <li>
              <strong>Weeks 1–6: Complete Development of VR Simulation</strong>
              <ul>
                <li>Address feedback from initial testing phases to refine the VR simulation.</li>
                <li>Ensure the VR simulation aligns with study objectives and Polya’s Problem-Solving Framework.</li>
                <li>Conduct usability tests to verify functionality, accessibility, and content accuracy.</li>
              </ul>
            </li>
            <li>
              <strong>Weeks 6–8: Data Collection</strong>
              <ul>
                <li>Conduct pre-assessments with all participants to establish baseline performance metrics.</li>
                <li>Facilitate VR sessions for the experimental group and traditional lecture-based sessions for the control group.</li>
                <li>Administer post-assessments after the intervention to gather performance data.</li>
              </ul>
            </li>
            <li>
              <strong>Weeks 6–9: Data Analysis & Interpretation</strong>
              <ul>
                <li>Aggregate data from pre- and post-assessments for statistical analysis.</li>
                <li>Compare the performance metrics of VR and control groups using t-tests and ANOVA.</li>
                <li>Interpret findings to assess the impact of VR on problem-solving efficiency, response time, and independence.</li>
              </ul>
            </li>
            <li>
              <strong>Weeks 8–12: Prepare Final Report and Paper</strong>
              <ul>
                <li>Synthesise findings into a cohesive final report.</li>
                <li>Develop a manuscript for submission to relevant academic journals.</li>
                <li>Prepare a presentation summarising the study for dissemination to stakeholders.</li>
              </ul>
            </li>
          </ul>
        
          <p>
            By adhering to this timeline, the project ensures systematic and efficient completion of all key objectives while maintaining high academic rigour. For a visualisation of our timeline, refer to the accompanying Gantt chart.
          </p>
          <img src="assets/Gantt Chart.jpg" alt="Our Projected Gantt Chart for Next Semester" class="gantt-chart">
  
        </div>
      </div>
  
      <br />
      <sl-divider></sl-divider>
      <div>
        <div id="section-header-9">
          <h2>9. Future Directions</h2>
          <p>
            This study establishes a robust foundation for exploring the transformative potential of Virtual Reality (VR) across educational and professional domains. Building upon the insights gained, several compelling avenues for future research and development emerge.
          </p>
        </div>
  
        <div id="sub-section-9-header-1">
          <h3>9.1 Enhancing VR Integration in Education</h3>
          <p>
            To facilitate the seamless integration of VR into educational curricula, future studies are required to evaluate the long-term effectiveness of VR-based learning. Key elements include:
          </p>
          <ul>
            <li>
              <strong>Accessibility Audits:</strong> Conduct usability studies to ensure VR platforms are intuitive and accessible to learners across different demographics and abilities.
            </li>
            <li>
              <strong>Longitudinal Impact Assessments:</strong> Implement studies tracking the long-term effects of VR-based training on professional competency and performance in real-world scenarios.
            </li>
          </ul>
          <p>
            Such tools will provide educators and researchers with reliable methodologies to assess and refine VR’s impact.
          </p>
        </div>
  
        <div id="sub-section-9-header-2">
          <h3>9.2 Harnessing Emerging Technologies</h3>
          <p>
            The integration of VR with emerging technologies promises unprecedented opportunities for innovation:
          </p>
          <ul>
            <li>
              <strong>Artificial Intelligence (AI):</strong> Use AI to create adaptive VR experiences tailored to individual learner profiles, enhancing personalization and effectiveness.
            </li>
            <li>
              <strong>Augmented Reality (AR):</strong> Combine AR and VR to develop mixed-reality solutions that seamlessly blend virtual and real-world elements, enriching the learning experience.
            </li>
            <li>
              <strong>Haptic Feedback Systems:</strong> Incorporate tactile and kinesthetic feedback to create highly immersive simulations, particularly valuable in surgical and mechanical training.
            </li>
          </ul>
          <p>
            This convergence of technologies will expand VR’s utility, making it an integral part of next-generation educational ecosystems.
          </p>
        
          <p>
            By pursuing these directions, future research can amplify VR’s transformative potential, creating immersive, accessible, and impactful learning experiences across disciplines. This study serves as a catalyst for advancing VR applications, fostering innovation in education, and addressing complex real-world challenges through experiential learning.
          </p>
        </div>
      </div>
  
      <br />
      <sl-divider></sl-divider>
      <div>
        <div id="section-header-10">
          <h2>10. Conclusion</h2>
          <p>
            This study underscores the transformative potential of VR in revolutionising medical education, with a particular focus on enhancing problem-solving skills in high-stakes scenarios like PPH. By systematically integrating Polya’s Problem-Solving Framework within immersive VR simulations, it not only bridges the gap between theoretical knowledge and practical application but also addresses critical limitations inherent in traditional pedagogical approaches. This alignment positions the study as a groundbreaking contribution to the evolving field of educational innovation.
          </p>
          <p>
            Through rigorous design, methodological precision, and empirical validation, this research establishes VR as a robust tool for cultivating cognitive adaptability, diagnostic precision, and procedural competence among medical students. Its findings reinforce the unique ability of VR to create controlled, dynamic, and repeatable learning environments that simulate real-world complexities without exposing learners to clinical risks. By fostering deep cognitive engagement and enabling active, experiential learning, this study challenges the over-reliance on passive instructional models and offers a tangible solution to critical educational shortcomings.
          </p>
          <p>
            Moreover, the research contributes a replicable, theory-driven framework for integrating immersive technologies into educational curricula across disciplines. By aligning VR’s interactivity with Cognitive Load Theory and Embodied Cognition, it demonstrates how experiential learning optimises cognitive load and strengthens schema development for problem-solving. This framework not only advances the field of medical training but also offers a template for VR’s application in diverse domains, ensuring its relevance and scalability.
          </p>
          <p>
            The study also acknowledges and confronts its limitations, such as resource constraints and the novelty effect associated with VR technology. By proposing actionable solutions such as preparatory tutorials, it addresses these barriers with foresight and pragmatism.
          </p>
          <p>
            Looking to the future, this research lays the foundation for interdisciplinary exploration of VR’s potential to enhance other critical cognitive domains, such as decision-making and creative problem-solving. Further studies could evaluate longitudinal impacts, incorporate adaptive AI for personalised learning pathways, and investigate hybrid integrations with augmented reality (AR) and other emerging technologies. These advancements will amplify VR’s potential as a universal educational tool, equipping learners with the cognitive resilience and practical expertise necessary to tackle complex, real-world challenges in an increasingly dynamic professional landscape.
          </p>
          <p>
            In conclusion, this study aims to transcend its initial scope by providing a pioneering framework for evidence-based innovation in education. It not only quantifies VR’s efficacy in advancing problem-solving skills but also sets a precedent for the thoughtful integration of immersive technologies into curricula. By enhancing cognitive efficiency and bridging learning gaps, VR represents a paradigm shift in how critical skills are taught, practised, and mastered, heralding a new era of transformative, learner-centric education.
          </p>
        </div>
      </div>
  
      <!-- This is an example of how you can use the references component to create references -->
      <div id="references" class="references">
        <sl-divider></sl-divider>
        <h2>11. References</h2>
        <ul>
          <li>
            Bienstock, J. L., Eke, A. C., & Hueppchen, N. A. (2021, April 29). Postpartum hemorrhage. <i>The New England Journal of Medicine</i>. <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10181876/" target="_blank">https://pmc.ncbi.nlm.nih.gov/articles/PMC10181876/</a>
          </li>
          <li>
            Say, L., Chou, D., Gemmill, A., Tunçalp, Ö., Moller, A.-B., Daniels, J., Gülmezoglu, A. M., Temmerman, M., & Alkema, L. (2024, June). Global causes of maternal death: a WHO systematic analysis. <i>The Lancet Global Health</i>. <a href="http://www.thelancet.com/journals/langlo/article/PIIS2214-109X(14)70227-X/fulltext?rss=yes" target="_blank">http://www.thelancet.com/journals/langlo/article/PIIS2214-109X(14)70227-X/fulltext?rss=yes</a>
          </li>
          <li>
            Farrar, J., & Aylward, B. (2023, October 11). Postpartum haemorrhage. <i>World Health Organization</i>. <a href="https://www.who.int/teams/sexual-and-reproductive-health-and-research-(srh)/areas-of-work/maternal-and-perinatal-health/postpartum-haemorrhage" target="_blank">https://www.who.int/teams/sexual-and-reproductive-health-and-research-(srh)/areas-of-work/maternal-and-perinatal-health/postpartum-haemorrhage</a>
          </li>
          <li>
            De Silva, M., Panisi, L., Lindquist, A., Cluver, C., Middleton, A., Koete, B., Vogel, J. P., Walker, S., Tong, S., & Hastie, R. (2021, July 20). Severe maternal morbidity in the Asia Pacific: A systematic review and meta-analysis. <i>BMC Pregnancy and Childbirth</i>. <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC8358707/" target="_blank">https://pmc.ncbi.nlm.nih.gov/articles/PMC8358707/</a>
          </li>
          <li>
            Wormer, K. C., Jamil, R. T., & Bryant, S. B. (2024, July 19). Postpartum hemorrhage. <i>StatPearls</i>. <a href="https://www.ncbi.nlm.nih.gov/books/NBK499988/" target="_blank">https://www.ncbi.nlm.nih.gov/books/NBK499988/</a>
          </li>
          <li>
            World Health Organization. (2023). Methods of assessing postpartum blood loss for the detection of postpartum haemorrhage: Evidence-to-decision framework. <i>WHO recommendations on the assessment of postpartum blood loss and use of a treatment bundle for postpartum haemorrhage [Internet]</i>. <a href="https://www.ncbi.nlm.nih.gov/books/NBK598973/" target="_blank">https://www.ncbi.nlm.nih.gov/books/NBK598973/</a>
          </li>
          <li>
            Toledo, P., McCarthy, R. J., Hewlett, B. J., Fitzgerald, P. C., & Wong, C. A. (n.d.). The accuracy of blood loss estimation after simulated vaginal delivery. <a href="https://pubmed.ncbi.nlm.nih.gov/18042876/" target="_blank">https://pubmed.ncbi.nlm.nih.gov/18042876/</a>
          </li>
          <li>
            Akter, S., Forbes, G., Miller, S., Galadanci, H., Qureshi, Z., Fawcus, S., Justus Hofmeyr, G., Moran, N., Singata-Madliki, M., Amole, T. G., Gwako, G., Osoti, A., Thomas, E., Gallos, I., Mammoliti, K.-M., Coomarasamy, A., Althabe, F., Lorencatto, F., & Bohren, M. A. (2022, October 26). Detection and management of postpartum haemorrhage: Qualitative evidence on healthcare providers’ knowledge and practices in Kenya, Nigeria, and South Africa. <i>Frontiers in Global Women's Health</i>. <a href="https://www.frontiersin.org/articles/10.3389/fgwh.2022.1020163/full" target="_blank">https://www.frontiersin.org/articles/10.3389/fgwh.2022.1020163/full</a>
          </li>
          
        </ul>
      </div>
    </div>
  
    <!-- This is the code to display the scroll to top button for ergonomic -->
    <!-- You can leave it as it is, or if you don't like its aesthetics you can also just delete it, -->
    <!-- but it might reduce the user experience. -->
    <sl-button class="scroll-to-top" variant="primary" size="medium" circle onclick="scrollToTop()">
      <sl-icon name="arrow-up" label="Settings"></sl-icon>
    </sl-button>
  
    <script src="https://unpkg.com/gridjs/dist/gridjs.umd.js"></script>
    <script type="module" src="./components/table-component/table-component.js"></script>
    <script src="gallery.js"></script>
  
  </body>
  
  </html>
  